# LLM Provider Configuration
LLM_PROVIDER=openai              # openai | anthropic | ollama
USE_MOCK_LLM=false               # true | false (set to true for cost-free testing)

# Mock Mode Configuration (Environment-Controlled)
USE_MOCK_MODE=false              # true | false (enable mock mode for MCP services when external services unavailable)
# Note: Mock modes are only activated when explicitly enabled via environment variables
# This ensures real service integration by default while allowing controlled testing

# OpenAI Configuration
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4o              # gpt-4o | gpt-4-turbo | gpt-3.5-turbo

# Anthropic Configuration
ANTHROPIC_API_KEY=sk-ant-your-key-here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022

# Ollama Configuration (for local development)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3

# Gemini Configuration (for invoice structured extraction)
GEMINI_API_KEY=AIzaSyCbqP2cDPd7KoZ257FRKWx336hGGSrz0q4
GOOGLE_API_KEY=AIzaSyCbqP2cDPd7KoZ257FRKWx336hGGSrz0q4  # Alternative name for Gemini API key
GEMINI_MODEL=gemini-2.5-flash-lite    # gemini-2.0-flash | gemini-2.5-flash | gemini-2.5-pro | gemini-2.5-flash-lite
GEMINI_TEMPERATURE=0.1

# Invoice Extraction Features
ENABLE_STRUCTURED_EXTRACTION=true  # Enable invoice structured extraction
EXTRACTION_VALIDATION=true          # Apply validation rules to extractions
EXTRACTION_REQUIRES_APPROVAL=true   # Require human approval before storing
ENABLE_EXTRACTION_VISUALIZATION=true  # Show langextract HTML visualization in iframe

# Validation Rule Overrides (optional - set to true/false to enable/disable specific rules)
# VALIDATION_RULE_date_ordering=true
# VALIDATION_RULE_total_calculation=true
# VALIDATION_RULE_line_items_sum=true
# VALIDATION_RULE_positive_amounts=true
# VALIDATION_RULE_required_fields=true
# VALIDATION_RULE_invoice_number_format=false
# VALIDATION_RULE_vendor_name_length=false
# VALIDATION_RULE_future_date_check=true
# VALIDATION_RULE_duplicate_line_items=false
# VALIDATION_RULE_tax_rate_reasonableness=true

# LLM Settings
LLM_TIMEOUT=60                   # seconds
LLM_MAX_RETRIES=2
LLM_TEMPERATURE=0.7

# MongoDB Configuration
MONGODB_URL=mongodb://localhost:27017
MONGODB_DATABASE=macae_db

# Server Configuration
HOST=0.0.0.0
PORT=8000
ENVIRONMENT=development

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Bill.com API Configuration
BILL_COM_BASE_URL=https://gateway.stage.bill.com/connect/v3/login 
#https://gateway.stage.bill.com
BILL_COM_USERNAME=ent.kgmc@gmail.com
BILL_COM_PASSWORD=National425@Jan
BILL_COM_ORG_ID=00802SHQTTGEIRXVek81
BILL_COM_DEV_KEY=01MVEQENZXWZIZHN1922
BILL_COM_ENVIRONMENT=stage
